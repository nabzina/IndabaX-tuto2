{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bases de l\"apprentissage automatique",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "SB0EeXzyu_sz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Les bases du machine learning"
      ]
    },
    {
      "metadata": {
        "id": "c9tLLZUyVwcV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "Dans cette pratique, nous introduisons l'idée de la classification (classer des choses en catégories) à l'aide d'un modèle d'apprentissage automatique. Nous explorons la relation entre les paramètres d'un classifieur et la frontière de décision (une ligne séparant les catégories) et introduisons également l'idée d'une fonction de perte. Enfin, nous introduisons brièvement Tensorflow.\n",
        "\n",
        "## Objectifs d'apprentissage\n",
        "* Comprendre l'idée de ** classification **\n",
        "* Comprendre le concept de  ** séparabilité linéaire** d'un jeu de données.\n",
        "* Comprendre ce que sont les ** paramètres ** d'un classificateur et leur lien avec la ** frontière de décision **\n",
        "* Être capable d'expliquer brièvement ** Tensorflow **."
      ]
    },
    {
      "metadata": {
        "id": "mHlHxAdBu7Dy",
        "colab_type": "code",
        "outputId": "df4e3bc6-6087-486b-c1ac-d3da3281750b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#@title [Execute moi!] Importation des librairies { display-mode: \"form\" }\n",
        "!pip install -q moviepy\n",
        "!pip install -q imageio\n",
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np                 # Numpy est une bibliothèque d'algèbre linéaire efficace.\n",
        "import matplotlib.pyplot as plt    # Matplotlib est utilisé pour générer des graphiques sur des données.\n",
        "from matplotlib import animation, rc\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "try:\n",
        "  tf.enable_eager_execution()\n",
        "  print('Execution immédiat')\n",
        "except ValueError:\n",
        "  print('Déja en mode execution immédiat, tu es dans le monde libre :)')\n",
        "  \n",
        "tfe = tf.contrib.eager"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Execution immediat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1xhQkS8A_KrJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## PLAN\n",
        "Dans cette session, nous nous attaquons à la tâche de ** classification ** d'un jeu de données simple et synthétique. La classification dans l'apprentissage automatique implique l'apprentissage d'une (ou plusieurs) catégories distinctes à des observations. Cela diffère d'une autre tâche courante dans l'apprentissage automatique appelée ** régression **, qui consiste à apprendre une correspondance entre des entrées et une sortie à valeur continue.\n",
        "\n",
        "1. Nous commençons par introduire un ensemble de données synthétiques de points rouges et bleus que nous souhaitons séparer(classification)\n",
        "2. Nous introduisons et explorons l'idée de ** séparabilité linéaire **\n",
        "3. Nous définissons une ** perte ** comme une mesure de la qualité d'un séparateur d'une ligne particulière\n",
        "4. Nous présentons brièvement TensorFlow et montrons comment l'utiliser pour rechercher automatiquement le minimum d'une fonction de perte."
      ]
    },
    {
      "metadata": {
        "id": "H020s1EsB_9p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title [EXECUTE MOI!] Fonction pour affichage de graphiques { display-mode: \"form\" }\n",
        "def plot_dataset(inputs, labels):\n",
        "  #Tracer les entrées 2D et les étiquettes données à l'aide de Matplotlib.   \n",
        "  plt.scatter(\n",
        "      inputs[:, 0], inputs[:, 1], \n",
        "      c=['red' if label > 0 else 'blue' for label in labels])\n",
        "\n",
        "  plt.axis('equal')\n",
        "\n",
        "  plt.xlabel('x1')\n",
        "  plt.ylabel('x2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3l1rLP3HufZv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Le jeu de données"
      ]
    },
    {
      "metadata": {
        "id": "FCu4YZy-uj0v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Exécutez le code dans la cellule ci-dessous, et regardez le tracé résultant. Il doit produire un ensemble de données 2D simple composé de 2 classes de points, les classes sont représentées par des couleurs bleus et rouges. Notre tâche est de construire un **classifieur binaire** qui peut distinguer les points rouges et bleus (le rouge et le bleu sont appelés les **classes** des points), en utilisant seulement les coordonnées 2-D d'un point. En d'autres termes, nous voulons une fonction qui prend en entrée un vecteur 2D représentant les coordonnées d'un point et retourne une valeur de 1 ou 0 indiquant si le point est rouge ou bleu. Nous avons ici **encodé** les couleurs rouge et bleu dans les chiffres 1 et 0 (ce qui facilite le travail en mathématiques et le code !)\n",
        "\n",
        "Note : nous avons arbitrairement encodé le rouge comme 1 et le bleu comme 0, vous pouvez le faire dans l'autre sens aussi longtemps que vous êtes constant !"
      ]
    },
    {
      "metadata": {
        "id": "2SrsrFSTtrl6",
        "colab_type": "code",
        "outputId": "1446442b-db11-4cd2-8feb-0441a127fc1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Générer le jeu de données  {run: \"auto\"}\n",
        "# Définir le(s) centre(s) des distributions normales\n",
        "centre = 1.9   #@param {type:\"slider\", min:0, max:2, step:0.1}\n",
        "\n",
        "points_in_class = 20  # Combien de points nous voulons par classe\n",
        "\n",
        "# Une graine aléatoire fixe est une \"astuce\" souvent utilisée en ML qui nous permet de recréer\n",
        "# les mêmes données quand il y a un élément aléatoire impliqué. \n",
        "np.random.seed(0)  \n",
        "\n",
        "# Générer des points aléatoires dans la classe \"rouge\"\n",
        "red_inputs = np.random.normal(loc=centre, scale=1.0, size=[points_in_class, 2])     \n",
        "\n",
        "# Générer des points aléatoires dans la classe \"bleu\"\n",
        "blue_inputs = np.random.normal(loc=-centre, scale=1.0, size=[points_in_class, 2]) \n",
        "\n",
        "# Mettons les deux groupes de points ensemble(=>jeu de données)\n",
        "inputs = np.concatenate((red_inputs, blue_inputs), axis=0) \n",
        "    \n",
        "# La classe (étiquette) est 1 pour le rouge ou 0 pour le bleu\n",
        "red_labels = np.ones(points_in_class)    \n",
        "blue_labels = np.zeros(points_in_class)\n",
        "labels = np.concatenate((red_labels, blue_labels), axis=0)\n",
        "\n",
        "# num_data_points est la taille totale du jeu de données\n",
        "num_data_points = 2 * points_in_class \n",
        "\n",
        "plot_dataset(inputs, labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFYCAYAAAB+s6Q9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "0_rhZC_HW_Wy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Pourquoi cette separation est aussi jolie ?"
      ]
    },
    {
      "metadata": {
        "id": "an9GF8nZWS4K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###À quoi ressemblent les données ? \n",
        "Les entrées sont des vecteurs bidimensionnels (points dans un espace 2D). Voici les coordonnées de 4 points, que nous avons délibérément choisis pour que les points 1 et 2 soient \"rouges\" et les points 3 et 4 \"bleus\". "
      ]
    },
    {
      "metadata": {
        "id": "5f8M-vQYWUuI",
        "colab_type": "code",
        "outputId": "d15f4ec2-ad13-45ef-9e9f-539399b0582b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "print('Input 1:\\t', inputs[0])\n",
        "print('Input 2:\\t', inputs[1])\n",
        "\n",
        "print('Input 3:\\t', inputs[-1])\n",
        "print('Input 4:\\t', inputs[-2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input 1:\t [2.36405235 1.00015721]\n",
            "Input 2:\t [1.57873798 2.8408932 ]\n",
            "Input 3:\t [-0.91155253 -0.54383466]\n",
            "Input 4:\t [-1.47079715 -1.17884966]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E14elwRYWoxB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Les labels sont 0 ou 1. Voici les labels correspondant aux points ci-dessus :"
      ]
    },
    {
      "metadata": {
        "id": "q4EJG8g4Wtih",
        "colab_type": "code",
        "outputId": "ff722300-bf88-4805-9625-054b85513fb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "print('Label 1:\\t', labels[0])\n",
        "print('Label 2:\\t', labels[1])\n",
        "\n",
        "print('Label 3:\\t', labels[-1])\n",
        "print('Label 4:\\t', labels[-2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label 1:\t 1.0\n",
            "Label 2:\t 1.0\n",
            "Label 3:\t 0.0\n",
            "Label 4:\t 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RyJ1PgtEFpa7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Bonus : Autres exemples de problèmes de classification binaire"
      ]
    },
    {
      "metadata": {
        "id": "7LAhNs_GFwOZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Dans cette session, nous utilisons un ensemble de données synthétiques où nous avons 2 classes de points 2D qui proviennent de différentes distributions, distinguées par les couleurs, rouge et bleu. Pour rendre cela plus concret, voici quelques exemples de problèmes de classification binaire plus réels.\n",
        "\n",
        "#### Question pour discussion\n",
        "Pour chacun des exemples ci-dessus, donnez les entrées et les labels\n",
        "\n",
        "* Déterminez si un message électronique  est SPAM ou PAS SPAM.\n",
        "* Déterminer si une image, représentée par ses valeurs de pixels codées est une image d'un CHIEN ou d'un CHAT.\n",
        "* Déterminer si la consommation d'énergie d'un bâtiment augmentera ou diminuera  le mois prochain, en utilisant une série chronologique des valeurs de consommation d'énergie passées \n"
      ]
    },
    {
      "metadata": {
        "id": "qNuMy1XwIJ-z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Séparabilité linéaire\n",
        "\n",
        "La séparabilité linéaire d'un ensemble de données D-dimensions avec 2 classes signifie qu'il existe une droite, plan ou hyperplan qui sépare les classes (un hyperplan est une généralisation d'une ligne droite à plusieurs dimensions). Dans ce cas, l'ensemble de données est bidimensionnel et **linéairement séparable** s'il est possible de tracer une ligne (1-D) entre les points rouge et bleu de sorte que tous les points rouges se trouvent d'un côté de la ligne et tous les points bleus de l'autre. \n",
        "\n",
        "#### Tâche exploratoire\n",
        "Dans la cellule de code sous la rubrique \"Le jeu de données\", changez le curseur pour la valeur \"centre\". Ceci mettra automatiquement à jour la valeur dans le code et redessinera le tracé.\n",
        "\n",
        "* quelle valeur du centre l'ensemble de données devient-il séparable linéairement ?\n",
        "\n",
        "\n",
        "#### Question pour discussion\n",
        "Pouvez-vous penser à des ensembles de données 2-D, 2 classes, similaires à celui ci-dessus, qui sont séparables (les points des 2 classes ne se chevauchent pas), mais qui ne sont pas **linéairement** séparables ? Dessinez quelques exemples sur papier ou tracez-les à l'aide de Matplotlib et discutez-en avec votre voisin et vos tuteurs. \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "tpM4lkGLdOW7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tracer la ligne(la frontiere de décision)\n",
        "\n",
        "Comme vous vous en souvenez à l'école(ou pas), une ligne en 2 dimensions, avec les axes de coordonnées $x_1$ et $x_2$, qui passe par l'origine (0, 0) peut être représentée par l'équation $w_1x_1 + w_2x_2 = 0$\n",
        "\n",
        "Nous pouvons aussi écrire ceci sous forme vectorielle comme : $\\mathbf{w}^T\\mathbf{x} = 0$, where $\\mathbf{w}^T = [w_1, w_2]$ and $\\mathbf{x}^T = [x_1, x_2]$.\n",
        "\n",
        "Lorsqu'une ligne (ou hyperplan) est définie de cette façon, on appelle les **paramètres**, $\\mathbf{w} = (w_1, w_2)$ un **vecteur normal** pour cette ligne. Le vecteur normal est orthogonal (perpendiculaire) à la ligne. Nous voulons construire une telle ligne qui sépare les points rouges et bleus, que nous appellerons une **frontiere de décision**. \n",
        "\n",
        "Dans la cellule suivante, nous traçons notre ensemble de données avec un vecteur normal $\\mathbf{w}$ et une frontiere de décision. Vous pouvez ajuster les valeurs de $w_1$ et $w_2$ en utilisant les curseurs à droite. Observez l'effet que les valeurs ont sur le vecteur normal dessiné en rouge* et la limite de décision en noir*. Ajustez les valeurs de façon à ce que la ligne noire sépare les points bleu et rouge (c'est-à-dire les points rouges d'un côté et bleus de l'autre). Votre ligne doit également avoir le vecteur normal pointant dans la direction des points rouges. La raison pour laquelle cette direction est importante est que nous voulons éventuellement **classifier** les points d'un côté de la ligne comme étant rouges et de l'autre comme étant bleus. \n",
        "\n",
        "Est-il possible de trouver une ligne à travers l'origine qui sépare parfaitement les points ?\n",
        "\n",
        "**Note** : Chacune de nos entrées est un vecteur 2D, composé de deux valeurs de coordonnées. Nous appelons ces 2 axes les coordonnées $x_1$ et $x_2$. Par exemple, si nous avons une entrée $(1, 2)$, alors nous dirions $x_1 = 1$ et $x_2 = 2$ pour ce point."
      ]
    },
    {
      "metadata": {
        "id": "TAXUNshcvPsg",
        "colab_type": "code",
        "outputId": "e0138ae8-cd57-45d0-e325-17daa549ace0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Effet des paramètres {run: \"auto\"}\n",
        "\n",
        "# Définir les paramètres\n",
        "w1 = 0.1 #@param { type: \"slider\", min: -5, max: 5, step: 0.1 }\n",
        "w2 = 1 #@param { type: \"slider\", min: -5, max: 5, step: 0.1 }\n",
        "\n",
        "plot_dataset(inputs, labels)\n",
        "\n",
        "# Ajoutez le vecteur des parametres au tracé. Nous le traçons en rouge, car il doit \"pointer\"\n",
        "# dans la direction des points rouges.\n",
        "ax = plt.axes()\n",
        "ax.arrow(0, 0, w1, w2, head_width=0.3, head_length=0.3, fc='r', ec='r')\n",
        "\n",
        "# Tracez une partie de la frontiere de décision en noir. Elle est orthogonale au vecteur normal.\n",
        "t = 2\n",
        "plt.plot([-t * w2, t * w2], [t * w1, -t * w1], 'k-')\n",
        "\n",
        "plt.xlim([-4, 4])\n",
        "plt.ylim([-4, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFcCAYAAADlIuYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "igAjsyMldbMr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Classification\n",
        "Étant donné un vecteur normal $\\mathbf{w}$, nous pouvons évaluer de quel côté de la frontiere de décision un point particulier $\\mathbf{x_i} = (x_{i,1}, x_{i, 2})$ se trouve en évaluant $\\mathbf{w^Tx_i}$. Si $\\mathbf{w^Tx_i} > 0$, le point $\\mathbf{x_i}$ se trouve d'un côté de la frontière (dans la direction du vecteur normal), et nous pouvons classer ce point dans la classe 1 (dans notre cas, \"rouge\"). Si $\\mathbf{w^Tx_i} < 0$, le point se trouve de l'autre côté et peut être classé dans la classe 0 (dans notre cas, \"bleu\"). Enfin, si $\\mathbf{w^Tx_i} = 0$, le point se trouve sur la frontiere de décision et nous pouvons décider si nous devons la classer comme 0 ou 1, ou l'ignorer. "
      ]
    },
    {
      "metadata": {
        "id": "jqW7RpSTaRZH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## A quel point la ligne(frontiere de decision) est-elle \"bonne\" ?\n",
        "\n",
        "Si vous avez joué avec le code ci-dessus, vous avez peut-être développé une certaine intuition sur la façon dont les différents réglages des paramètres influencent l'emplacement final de la frontiere de décision. Le but de l'apprentissage machine est d'ajuster *automatiquement* les valeurs de $w_1$ et $w_2$ pour trouver une frontiere de décision appropriée ! Mais pour ce faire, il faut spécifier mathématiquement une fonction de **perte** ou **objectif**. La perte est une fonction des paramètres $w_1$ et $w_2$ et nous indique dans quelle mesure une certaine configuration des valeurs des paramètres est bonne pour classer les données. Cette fonction est définie de telle sorte qu'elle atteigne son réglage optimal lorsqu'elle est minimisée, c'est-à-dire  plus sa valeur est *petite*, le *mieux* est la séparation entre les classes. Une propriété supplémentaire qu'une fonction de perte peut avoir et qui est souvent cruciale pour l'apprentissage machine est d'être *différentiable*. Une fonction de perte différentiable nous permet d'utiliser *l'optimisation basée sur les dérivées* pour trouver son minimum et les valeurs optimales correspondantes de $w_1$ et $w_2$. \n",
        "\n",
        "Pour ce problème de classification, nous considérons la fonction de perte **entropie  croisée binaire** pour mesurer la qualité des prédictions du modèle.  Cette fonction de perte compare la prédiction du modèle pour chaque exemple, $\\mathbf{x_i}$ à la vraie **cible** $y_i$ (on appelle souvent la vraie étiquette associée à une entrée \"label\"). Il applique ensuite la fonction log (non linéaire) pour pénaliser le modèle parce qu'il est plus éloigné de la classe réelle. L'équation pour la perte d'entropie croisée binaire, sur un ensemble de données avec  $N$ points est :\n",
        "\n",
        "\\begin{align}\n",
        "p(\\mathbf{w}) = -\\frac{1}{N}\\sum_{i=1}^N y_i log(\\hat{y}_i) + (1-y_i)log(1-\\hat{y}_i)\n",
        "\\end{align}\n",
        "\n",
        "où $\\hat{y}_i = \\operatorname{sigmoid}(\\mathbf{w}^T\\mathbf{x_i})$ et la fonction  $\\operatorname{sigmoid}$ est définie ainsi :\n",
        "\n",
        "$$\n",
        "\\mathrm{sigmoid}(a) = \\frac{1}{1 + e^{-a}} .\n",
        "$$\n",
        "\n",
        "La raison pour laquelle nous utilisons la fonction  $\\operatorname{sigmoid}$ est que notre classifieur peut sortir n'importe quelle valeur réelle. La fonction de perte d'entropie croisée binaire, cependant, s'attend à ce que les prédictions faites par un classifieur se situent entre $0$ et $1$. La fonction  $\\operatorname{sigmoid}$ \"remplace\" toutes les entrées de nombres réels pour se situer dans l'intervalle $(0,1)$.\n",
        "\n",
        "Enveloppons maintenant ceci dans une fonction Python pour que nous puissions calculer la perte pour n'importe quelle valeur de $w_1$ et $w_2$ :\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "wKkpBZ6ZWLoF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_loss(w1, w2):\n",
        "  \n",
        "  total_log_likelihood = 0  \n",
        "  \n",
        "  # Ajouter la contribution de chaque point de données à la perte\n",
        "  for (x1, x2), target in zip(inputs, labels):\n",
        "    # Comme nos labels sont 0 ou 1, notre fonction de prédiction doit fournir une valeur entre 0 et 1.\n",
        "    # La fonction sigmoïde'remplace' toute sortie par une valeure comprise entre 0 et 1 :\n",
        "    prediction = tf.sigmoid(w1*x1 + w2*x2)  \n",
        "    \n",
        "    # Calculez la perte locale\n",
        "    # Nous ajoutons 1e-10 pour rendre les opérations du log numériquement stables (c'est-à-dire éviter de prendre le log de 0.)\n",
        "    log_likelihood = target * tf.log(prediction + 1e-10) + (1.-target)*tf.log(1.-prediction + 1e-10)\n",
        "    total_log_likelihood += log_likelihood\n",
        "  \n",
        "  loss = -total_log_likelihood\n",
        "  average_loss = loss / len(inputs)\n",
        "  return average_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x2P-s50pgj-N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### En savoir plus sur la fonction sigmoïde"
      ]
    },
    {
      "metadata": {
        "id": "AQqQ_quqwCFF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "La fonction sigmoid est definit ainsi\n",
        "$$\n",
        "\\mathrm{sigmoid}(a) = \\frac{1}{1 + e^{-a}} .\n",
        "$$\n",
        "Pouvez vous demontrer que\n",
        "$$\n",
        "1 - \\mathrm{sigmoid}(a) = \\frac{1}{1 + e^{a}} ,\n",
        "$$\n",
        "et les points suivants sur un papier?\n",
        "\n",
        "* Quelle est sa valeur quand $a = \\mathbf{w}^{T}\\mathbf{x}$ est positif ? négatif ? et zéro ?\n",
        "* Qu'arrive-t-il à sa valeur quand $a = \\mathbf{w}^{T}\\mathbf{x}$ devient plus grand ?\n",
        "* Quelle est la valeur de $\\mathrm{sigmoid}(\\mathbf{w^Tx})$ quand $\\mathbf{w}^T\\mathbf{x} = 0$ ? En quoi cela change-t-il la façon dont nous classons les points de part et d'autre de la frontiere de décision ?\n",
        "\n",
        "Après avoir répondu aux questions ci-dessus, expliquez à votre voisin pourquoi la fonction  de perte d'entropie binaire croisée a un sens. \n",
        "\n",
        "**INDICE *** : Rappelez-vous que l'idée de la fonction de perte est de retourner de petites valeurs lorsque le classifieur fait de bonnes prédictions et de grandes valeurs lorsque le classifieur fait de mauvaises prédictions. "
      ]
    },
    {
      "metadata": {
        "id": "x46fjqTUf4Dj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Question bonus\n",
        "Nous avons dérivé la fonction `compute_loss()` ci-dessus basée sur la minimisation de la perte log-loss de l'erreur de prédiction. Ceci est lié à un concept appelé 'cross-entropy'. Mais une autre façon de dériver exactement la même fonction de perte est de maximiser la probabilité des données sous le modèle $P(y | x, w_1, w_2)$. Si vous êtes familier avec ce concept (par exemple à partir de statistiques), voyez si vous pouvez le déduire de cette façon également."
      ]
    },
    {
      "metadata": {
        "id": "0tJJrBynf6ms",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Valeur de la fonction de perte pour les $w_1$ et $w_2$ que vous avez choisis\n"
      ]
    },
    {
      "metadata": {
        "id": "edKlqlACgFsE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "La ligne de code suivante calcule la valeur de perte pour les valeurs $w_1$ et $w_2$ que vous avez choisies. Essayez de changer les valeurs de $w_1$ et $w_2$ en utilisant les curseurs ci-dessus et reexecuter la ligne ci-dessous. Pouvez-vous voir comment une meilleure séparation se traduit par une perte moindre ? \n",
        "\n",
        "Remarque : Si vous avez déjà utilisé TensorFlow auparavant, le fonctionnement de cette cellule de code peut prêter à confusion ! Nous vous en dirons plus à ce sujet plus tard.... "
      ]
    },
    {
      "metadata": {
        "id": "QyzwKx6ef_Vm",
        "colab_type": "code",
        "outputId": "e01e095c-28fe-490a-dac9-171eee9b0ca5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "compute_loss(w1, w2).numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1344592384871101"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "Z9KAMYSUgmkM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Visualisation de la fonction de perte"
      ]
    },
    {
      "metadata": {
        "id": "ukphZS4_hMgN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Nous pouvons visualiser la fonction de perte pour notre ensemble de données en traçant sa valeur à chaque point d'une grille entière de valeurs de paramètres $w_1$ et $w_2$. Pour ce faire, nous utilisons un **graphique de contour**, qui est une technique permettant de visualiser une fonction 3D sur un graphique 2D en laissant la couleur représenter la troisième dimension. Tous les points de la même couleur ont la même valeur de perte. "
      ]
    },
    {
      "metadata": {
        "id": "y4HZS5zZt3Pu",
        "colab_type": "code",
        "outputId": "ba909c3c-7282-478e-9685-575b1a6a5903",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "cell_type": "code",
      "source": [
        "# Nous définissons une fonction pour pouvoir réutiliser ce code plus tard\n",
        "def plot_contours():  \n",
        "  # Générer tout un tas de points (w1, w2) dans une grille\n",
        "  ind = np.linspace(-5, 5, 50)\n",
        "  w1grid, w2grid = np.meshgrid(ind, ind)\n",
        "\n",
        "  # Calculez la perte pour chaque point de la grille\n",
        "  losses = []\n",
        "  for w1s, w2s in zip(w1grid, w2grid):\n",
        "    loss = compute_loss(w1s, w2s)\n",
        "    losses.append(loss)\n",
        "\n",
        "  # Regroupez les pertes pour chaque valeur de w1 et w2 dans un seul tableau (50,50).\n",
        "  losses_array = np.concatenate(losses).reshape(50,50)\n",
        "\n",
        "  # Tracez maintenant la fonction de perte résultante sous la forme d'un tracé de contour sur l'ensemble de la grille des valeurs (w1, w2).\n",
        "  fig = plt.figure()\n",
        "  plt.contourf(w1grid, w2grid, losses_array, 20, cmap=plt.cm.jet)\n",
        "  cbar = plt.colorbar()\n",
        "  cbar.ax.set_ylabel(u\"Valeur  de la perte d'entropie binaire croisée\")\n",
        "  plt.xlabel(u'valeure de w1')\n",
        "  plt.ylabel(u'valeure de w2')\n",
        "  plt.title(u'Perte totale pour différentes valeurs de w1 et w2')\n",
        "\n",
        "plot_contours()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdkAAAFnCAYAAADqhzMHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMJEsAEwkCwATyQLAJG0JuzQC5qqZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "676bWBwTiXXD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Optimiser le perte avec TensorFlow"
      ]
    },
    {
      "metadata": {
        "id": "MMLA-wk5xB7p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Maintenant que nous avons une fonction qui nous donne la perte pour différentes valeurs de $w_1$ et $w_2$, nous voulons une méthode automatisée pour trouver les valeurs qui minimisent la fonction de perte. C'est là qu'intervient l'optimisation par **descente de gradient**. L'idée est que pour chaque (lot de) points de données, nous calculons la perte en utilisant les valeurs actuelles de $w_1$ et $w_2$ sur les données. Nous calculons ensuite le **gradient** (ou dérivé) de la fonction de perte aux valeurs actuelles de $w_1$ et $w_2$. Le négatif du gradient pointe dans la direction de *la descente la plus abrupte* le long de la fonction de fonction de perte. En ajustant les valeurs de $w_1$ et $w_2$ dans la direction négative du gradient, on se rapproche du minimum de la fonction de perte (à condition que la fonction de perte soit \"bien conduite\"). L'importance(la magnitude) d'un pas que nous franchissons est déterminée par le **taux d'apprentissage**. Pour le faire plus facilement, nous utiliserons TensorFlow.\n"
      ]
    },
    {
      "metadata": {
        "id": "sFJBmN5Hivhv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Un peu de litterature: TensorFlow"
      ]
    },
    {
      "metadata": {
        "id": "DRtDggkBi0X3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TensorFlow (TF) est une bibliothèque logicielle open source pour le calcul numérique utilisant le concept des tenseurs. Vous pouvez considérer les tenseurs comme une généralisation des matrices à des dimensions plus élevées, ou à peu près équivalentes à des tableaux multidimensionnels. Les scalaires sont des tenseurs 0-dimensionnels, les vecteurs sont 1-dimensionnels, les matrices standard sont 2-dimensionnels, et les tenseurs supérieurs ont 3 dimensions ou plus. Vous pouvez considérer les dimensions comme représentant des groupes de nombres qui signifient la même chose. Par exemple, pour les images, nous utilisons souvent des tenseurs tridimensionnels où la première dimension représente les canaux de couleur rouge, vert et bleu de l'image, et les deux suivantes sont les colonnes et lignes de pixels de l'image. \n",
        "\n",
        "**Note** : Ne soyez pas confus quand on dit \"vecteur 2D\" ou \"vecteur 3D\", qui fait référence à un tenseur unidimensionnel de taille 2 ou 3.\n",
        "\n",
        "L'avantage majeur de l'utilisation de TensorFlow est qu'il peut dériver automatiquement les gradients de nombreuses expressions mathématiques impliquant des tenseurs. Elle y parvient grâce à un processus appelé \" différentiation automatique \". Tensorflow prend également en charge plusieurs \" noyaux \", ce qui vous permet d'exécuter facilement votre code sur des processeurs normaux (CPU), des cartes graphiques (GPU) et d'autres accélérateurs matériels plus exotiques comme les Tensor Processing Units (TPU) de Google.\n",
        "\n",
        "Tensorflow propose en fait **deux modes de fonctionnement**, le premier, appelé \"mode graphique\", construit un graphique de calcul à l'avance, puis introduit les données dans le graphique. En construisant le graphique à l'avance, Tensorflow peut appliquer des optimisations au graphique qui lui permettent d'extraire les performances maximales du matériel sur lequel vous travaillez. Vous aurez rencontré ce mode si vous avez utilisé Tensorflow avant ou pendant l'Indaba l'année dernière ! Le second mode, appelé [\"Eager-mode\"](https://www.tensorflow.org/guide/eager), est beaucoup plus récent et évalue les opérations de Tensor impérativement (dans l'ordre où vous les écrivez), comme NumPy et PyTorch. Le mode Eager est un peu moins performant mais beaucoup plus intuitif, surtout si vous n'avez jamais utilisé un style de programmation \"define-and-run\" (comme le mode graphique) auparavant, et est donc le mode que nous allons utiliser dans ces pratiques. "
      ]
    },
    {
      "metadata": {
        "id": "eLVl2PhK2VpP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Utiliser Tensorflow pour optimiser la fonction de perte\n",
        "Nous utilisons TensorFlow pour optimiser les paramètres du modèle avec la descente de gradient. Nous bouclons sur l'ensemble de données plusieurs fois (appelées \"épochs\") et traçons la frontiere de décision finale ainsi qu'un graphique montrant comment les paramètres et la perte ont changé au cours des époques.\n",
        "\n",
        "**Note** : TensorFlow est probablement exagéré pour cet exemple, car le gradient(derivee) est très facile à calculer, mais nous l'introduisons ici parce qu'il deviendra essentiel de calculer les gradients de modèles plus complexes dans les pratiques ultérieures ! "
      ]
    },
    {
      "metadata": {
        "id": "cKre-CI8IG9z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr = 0.25  # Le taux d'apprentissage\n",
        "\n",
        "# Initialiser les variables Tensorflow représentant nos paramètres.\n",
        "# Nous devons utiliser des variables TensorFlow ici plutôt que des variables Numpy ou Python\n",
        "# que TensorFlow est capable de calculer des gradients.\n",
        "w1 = tfe.Variable(-2.0)  \n",
        "w2 = tfe.Variable(-4.0)  \n",
        "\n",
        "plot_contours()\n",
        "\n",
        "# Bouclez sur l'ensemble de données plusieurs fois\n",
        "parameter_values = []\n",
        "for epoch in range(20):\n",
        "  plt.scatter(w1.numpy(), w2.numpy(), marker='o', color='black')\n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = compute_loss(w1, w2)\n",
        "  \n",
        "  # Maintenant, nous faisons un pas dans l'espace des paramètres dans la direction inverse du gradient pour rapprocher les paramètres (espérons-le !) de leur valeur optimale.\n",
        "  dw1, dw2 = tape.gradient(loss, [w1, w2])\n",
        "  \n",
        "  # Nous y parvenons en soustrayant lr * dw1 et lr * dw2 des variables w1 et w2\n",
        "  w1.assign_sub(lr*dw1)\n",
        "  w2.assign_sub(lr*dw2)\n",
        "  \n",
        "print('Optimisation terminée, les valeurs finales de w1 et w2 sont :')\n",
        "print(w1.numpy(), w2.numpy())\n",
        "\n",
        "# Plot the final point on the loss surface.\n",
        "plt.scatter(w1.numpy(), w2.numpy(), marker='x', color='red')\n",
        "plt.show()\n",
        "\n",
        "# Tracer la frontiere de décision finale\n",
        "plot_dataset(inputs, labels)\n",
        "ax = plt.axes()\n",
        "ax.arrow(0, 0, w1.numpy(), w2.numpy(), head_width=0.3, head_length=0.3, fc='r', ec='r')\n",
        "plt.plot([-2 * w2.numpy(), 2 * w2.numpy()], [2 * w1.numpy(), -2 * w1.numpy()], 'k-')\n",
        "\n",
        "plt.xlim([-4, 4])\n",
        "plt.ylim([-4, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "meoIDXSQjKeE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Comment les valeurs finales de $w_1$ et $w_2$ trouvées par Tensorflow correspondent-elles à celles trouvées manuellement ? \n",
        "\n",
        "## Tâches facultatives\n",
        "Si vous avez répondu à toutes les questions et que vous avez l'impression d'avoir une bonne compréhension de ce qui se passe, essayez les tâches suivantes :\n",
        "\n",
        "1. Ajoutez un paramètre **bias** à l'équation de la limite de décision et visualisez comment cela modifie la frontiere de décision, la fonction de perte et la solution finale trouvée par Tensorflow.\n",
        "2. Ajoutez un **régulateur**, par exemple le Régulateur L2 (voir l'annexe ci-dessous pour plus d'informations) - comment affecte-t-il le tracé du contour des paramètres par rapport à la fonction de perte ? Comment la modification de la force de régularisation influe-t-elle sur la perte ? \n"
      ]
    },
    {
      "metadata": {
        "id": "SVFq4xvBmGQq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Les prochaines étapes\n",
        "Jetez un coup d'œil à[la pratique de l'année dernière](https://github.com/deep-learning-indaba/practicals2017/blob/master/practical1.ipynb) qui adopte une approche plus \"ascendante\", couvre plus de détails sur la façon dont les gradients sont calculés et examine également un problème de classification multi-classe avec une frontiere de décision non linéaire. \n",
        "\n",
        "Attention, c'est en mode graphe :(\n"
      ]
    },
    {
      "metadata": {
        "id": "4jpKVuEkQF46",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Annexe"
      ]
    },
    {
      "metadata": {
        "id": "EgLuuVNRQHqy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Régulateur L1 et L2"
      ]
    },
    {
      "metadata": {
        "id": "SlO75RlmQKQF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Deux des méthodes de régularisation les plus simples sont la régularisation L1 et la régularisation L2 (vous avez peut-être entendu parler de régression _Lasso_ et _Ridge_ si vous avez déjà utilisé la régression linéaire). Ces deux méthodes régularisent le modèle en ajoutant un terme à la perte qui pénalise le modèle s'il devient trop complexe.\n",
        "La régularisation L1 ajoute un terme basé sur la norme L1 :\n",
        "\n",
        "\n",
        "$perte_{L1} = perte + \\lambda \\sum_i |w_i|$\n",
        "\n",
        "où $\\lambda$ est un paramètre qui contrôle le taux de régularisation, et $w_i$ sont les paramètres du modèle. La régularisation de L1 a pour effet de forcer certains paramètres à se réduire à 0, ce qui les élimine effectivement du modèle.\n",
        "\n",
        "La régularisation L2 ajoute également un terme basé sur la norme L2 :\n",
        "\n",
        "$perte_{L2} = perte + \\lambda \\sum_i w_i^2$.\n",
        "\n",
        "La régularisation L2 a pour effet d'éviter que l'un ou l'autre des paramètres ne devienne trop grand et _surpuissant_ les autres. \n",
        "\n",
        "Dans certains cas, il peut être utile d'utiliser à la fois la régularisation L1 et L2(ElasticNet). \n",
        "\n"
      ]
    }
  ]
}